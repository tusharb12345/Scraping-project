{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceeff3a-7398-4e78-b390-24a2135bd99c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0865ca0-6a74-4ad7-a45b-c86b321f84dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://audiobooks.3xforum.ro/post/2228/Devon_C_Ford/\"\n",
    "webpage = requests.get(url, proxies = {'http' : 'http://38.54.71.67:80'})\n",
    "soup = bs(webpage.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84951b5a-d7a9-46bd-af2a-822d347f14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getName(soup):\n",
    "\n",
    "    try:\n",
    "        b = soup.find_all(\"table\", attrs={'class':'punspacer'})\n",
    "        b2 = b[0].find('b').text\n",
    "        name_value=b2\n",
    "\n",
    "    except:\n",
    "        name_value = ''\n",
    "    return name_value\n",
    "\n",
    "def getDescription(soup):\n",
    "    try:\n",
    "        des = soup.find(\"span\", attrs={'class':'puntext'})\n",
    "        des_val = des.text\n",
    "    except:\n",
    "        des_val = ''\n",
    "    return des_val\n",
    "\n",
    "def getCode1(soup):\n",
    "    try:\n",
    "        code = soup.find(\"pre\")\n",
    "        code_val = code.text\n",
    "    except:\n",
    "        code_val = ''\n",
    "    return code_val\n",
    "\n",
    "def getBooks(soup):\n",
    "    try:\n",
    "       l1 = soup.find_all(\"span\", attrs={'class':'puntext'})[2]\n",
    "       l1 = str(l1).replace(\"<br/>\", \"/n\" ).split(\"/n\")\n",
    "       substring = \"span\" \n",
    "       for x in l1:\n",
    "            filtered_list = [x for x in l1 if substring not in x]\n",
    "       filtered_list = [x for x in filtered_list if x]\n",
    "       substrings_to_remove = [\"Series\"]\n",
    "       fl= [x for x in filtered_list if not any(substring in x for substring in substrings_to_remove)]\n",
    "       r = \"\\n\".join(filtered_list)\n",
    "       des_val = r\n",
    "    except:\n",
    "        des_val = ''\n",
    "    return des_val\n",
    "\n",
    "def getCode2(soup):\n",
    "    try:\n",
    "        code = soup.find_all(\"pre\")[1]\n",
    "        code_val = code.text\n",
    "    except:\n",
    "        code_val = ''\n",
    "    return code_val\n",
    "\n",
    "def getBooksQuantity(soup):\n",
    "    try:\n",
    "       l1 = soup.find_all(\"span\", attrs={'class':'puntext'})[2]\n",
    "       l1 = str(l1).replace(\"<br/>\", \"/n\" ).split(\"/n\")\n",
    "       substring = \"span\" \n",
    "       for x in l1:\n",
    "            filtered_list = [x for x in l1 if substring not in x]\n",
    "       filtered_list = [x for x in filtered_list if x]\n",
    "        \n",
    "       substrings_to_remove = [\"Series\", \"Books\", \"strong\", \"SERIES\"]\n",
    "       fl= [x for x in filtered_list if not any(substring in x for substring in substrings_to_remove)]\n",
    "       count_val = fl\n",
    "    except:\n",
    "       count_val = ''\n",
    "    return len(count_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e8b0f-dffe-4621-9e5f-542f16cc1af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "getBooksQuantity(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db9abb-cfdb-48c5-a8b7-ea412e95091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"validproxies.txt\") as f:\n",
    "    proxies = f.read().split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c756c-21f4-460b-948b-cb8d7b4fff1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'http://audiobooks.3xforum.ro/topic/2/AUDIOBOOKS/40/'\n",
    "\n",
    "c = 0\n",
    "for i in proxies:\n",
    "    try:\n",
    "        webpage = requests.get(url, proxies = {'http' : 'http://' + proxies[c]})\n",
    "        soup = bs(webpage.content, 'html.parser')\n",
    "\n",
    "        a = soup.find_all(\"tr\", attrs={'class':'puntopic'})\n",
    "        link_list = []\n",
    "        for i in a:\n",
    "            b = i.find_all('td', attrs={'class':'puncon2'})\n",
    "            link_list.append(b[1].find(\"a\").get(\"href\"))\n",
    "\n",
    "        d = {'Author':[], \"About\":[], \"code\":[], \"Books\":[], \"code2\":[], \"BooksQuantity\":[]}\n",
    "        counter = 0\n",
    "        for link in link_list:\n",
    "            try:\n",
    "                new_webpage2 = requests.get('http://audiobooks.3xforum.ro/' + link, proxies = {'http' : 'http://' + proxies[counter]})\n",
    "                print(\"Proxy Passed \" + proxies[counter])\n",
    "                new_soup = bs(new_webpage2.content, 'html.parser')\n",
    "                d['Author'].append(getName(new_soup))\n",
    "                d['About'].append(getDescription(new_soup))\n",
    "                d['code'].append(getCode1(new_soup))\n",
    "                d['Books'].append(getBooks(new_soup))\n",
    "                d['code2'].append(getCode2(new_soup))\n",
    "                d['BooksQuantity'].append(getBooksQuantity(new_soup))\n",
    "                print(\"Success\")\n",
    "            except:\n",
    "                print(\"proxy Failed\" + proxies[counter])\n",
    "                counter+=1\n",
    "        break\n",
    "    except:\n",
    "        c+=1\n",
    "        print(\"failed\")\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df['Author'] = df['Author'].str.replace(\"AUDIOBOOKS / AUDIOBOOKS / \", \"\")\n",
    "\n",
    "\n",
    "columns = {'Author':30, \"About\":150, \"code\":70, \"Books\":110, \"code2\":80, \"BooksQuantity\":15}\n",
    "df.to_excel(\"Data.xlsx\")\n",
    "print(\"Success2\")\n",
    "# if df.loc[\"Author\" == 'Andrea Cremer']:\n",
    "#     print(\"Hurray!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecedc3b-41ec-490e-a346-691be604ef65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
